# Open Moderator

With the recent revelations of politically motivated censorship, failings of large social media platforms, and inherent biases in content moderation, it has become apparent that content moderation cannot be left up to corporate interests, government agencies, and other sources of corruption. To that end, the Open Moderator project seeks to resolve these problems through advanced tools and drop-in replacements for social media companies.

## Mission
Our mission is to provide impartial and equitable content moderation services that promote free speech, foster meaningful dialogue, and ensure user safety. We will ensure that all content is moderated in a fair, balanced, and unbiased manner, based on established rules and guidelines. We will strive to provide the highest level of content moderation services, while respecting the rights of all users.

## Censorship vs Moderation
Censorship and moderation are two separate concepts that cannot coexist in the same space. Censorship involves blocking or limiting the content that can be accessed or shared, while moderation is about creating a safe and respectful environment free of violence and criminal conduct. Censoring prevents users from having access to information they may need or want while moderation is about providing a platform for open and respectful dialogue. Censorship restricts the flow of information and can also limit the userâ€™s freedom of expression, while moderation empowers users to express their thoughts and opinions in a safe and respectful way.

## Freedom of Speech
Freedom of speech is the pillar of Western civilization, and a core tenant of Open Moderator. It is neither the desire nor the goal that any of these tools be used to stifle the free expression of ideas, nor to be the arbiter of what is or isn't "misinformation" as many are wont to do, but to remove only that speech which is obscene per United States Supreme Court rulings and to provide a fully auditable and turn key system that is fair and balanced for all parties involved. To that end, any moderation must be made with the greatest consideration for the individual and intrinsic human right to freely express oneself, and any actions taken must be proprotional to the level of damage speech causes. This is itself a subjective matter, and so the only reasonable course of action is one that allows for only the censorship of the obscene - that is - we may only censor that which is offensive/disgusting by society. This, again, is subjective, but there is of course some content which is always obscene (e.g. chld abuse).

## Who defines obscenity?
Regional differences in sensibilities have been noted for centuries, and so it is most logical that the people of a given society/region will determine for themselves what is and is not obscene speech. This draws on another Western philosophical principle which forms the pillar of Open Moderator: Governments are instituted among men by the consent of the governed. To police the speech of any person requires his or her consent, and while social media sites and search engines have gotten away with violating this principle, it is an unmaintainable and reprehensible violation of fundamental human rights.

## Who does the moderation?
There are a few primary paths which are being explored at the moment. The first would create a jury system in which community members would be randomly selected to make deliberations and vote on whether a given piece of content is in violation of basic decency, the second is to completely automate the process of moderation. It is highly likely that the final product of Open Moderator will combine both of these into a single application.
